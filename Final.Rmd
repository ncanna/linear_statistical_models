---
title: "Final" 
author: "Navya Annapareddy"
fontsize: 12pt
geometry: margin=1in
urlcolor: black
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, highlight=FALSE)
#library(tidyverse)
library(ggplot2)
library(ggpubr)
require(dplyr) 
library(ade4)
library(lattice) 
library("GGally")
library(MASS)
library(lindia)
library(readr)
library(plotly)
library(gtools)
library(tseries)
library(imputeTS)
library(forecast)
library(mtsdi)
library(lubridate)
library("car")
library(ggfortify)

sourcedir <-"~/Desktop/Fall 2020 Classes/SYS4021/Source" 
setwd(sourcedir)
source("AccidentInput.R")
source("SPM_Panel.R")
source("PCAplots.R")
source("FactorPlots.R")
source("ROC.R")
source("pc.glm.R")
source("TestSet.R")
```

# Part 1
```{r message=FALSE, warning=FALSE}
setwd("~/Desktop/Fall 2020 Classes/SYS4021/Source")
app <- read.table("app.csv", sep = ",", header = T)
head(app)
```
```{r}
dim(app)
```

```{r}
boxplot(app$Price, plot=FALSE)$out
```

```{r}
boxplot(app$Price, plot=FALSE)$stats
```

```{r}
ggplot(app, aes(x="", y=Price)) + 
  geom_boxplot(width=0.6) +
  stat_summary(
    aes(label=sprintf("%1.1f", ..y..)),
    geom="text", 
    fun.y = function(y) boxplot.stats(y)$stats,
    position=position_nudge(x=0.33), 
    size=3.5) +
  theme_bw()
```

```{r include=FALSE}
panel.cor <- function(x, y, digits=2, prefix="", cex.cor)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- round(abs(cor(x, y, use = "complete.obs")), 2)
    txt <- format(c(r, 0.123456789), digits=digits)[1]
    txt <- paste(prefix, txt, sep="")
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = 2)
}

panel.hist <- function(x, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FsALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y,
    col="steelblue2", ...)
}


uva.pairs <- function(vars, ...)
{
	args <- list(...)
	
	if(is.matrix(vars) | is.data.frame(vars)){
		if(is.null(args$labels))pairs(vars, lower.panel = panel.smooth, upper.panel = panel.cor, diag.panel = panel.hist, main = args$main)
		else(pairs(vars, lower.panel = panel.smooth, upper.panel = panel.cor, diag.panel = panel.hist, main = args$main, labels = args$labels))
		}
	else(if(is.character(vars)){
		if(is.null(args$labels))pairs(formula(vars), lower.panel = panel.smooth, upper.panel = panel.cor, diag.panel = panel.hist, main = args$main, data = args$data)
		else(pairs(formula(vars), lower.panel = panel.smooth, upper.panel = panel.cor, diag.panel = panel.hist, main = args$main, data = args$data, labels = args$labels))} 
	else(cat("You must enter a matrix, dataframe or formula")))
	}
```

```{r}
names(app)
```

```{r}
app$Platform <- as.factor(app$Platform)
uva.pairs(app[,c("Price", "Platform", "Develop", "X5Star", "CompSites", "Date", "Advert", "Users")])
```
```{r}
contrasts(app$Platform)
```

```{r}
app.inter <-lm(Price~(Platform + Users)^2,data=app)
summary(app.inter)
```

```{r}
AIC(app.inter)
```

```{r}
names(app)
```

```{r}
app.main <-lm(Price~Platform + Develop + X5Star + CompSites + Date + Advert + Users,data=app)
summary(app.main)
```

```{r}
AIC(app.main)
```

```{r}
anova(app.main,app.inter)
```
p < 0.01
Does significantly affect 
Use complexity and choose larger

```{r}
anova(app.inter,app.main)
```

```{r}
gg_cooksd(app.main, label = TRUE, show.threshold = TRUE,
          threshold = "convention") +
  xlab("Obs. Number")+ylab("Cook's distance") +
  ggtitle("Cook's distance plot")+
  theme(plot.title = element_text(hjust = 0.5), plot.caption = element_text(hjust = 0.5))
```

```{r}
plot(app.main,labels.id = NULL)
```

```{r}
# Residual vs. Fitted
plot(app.main,which=1) 
```
```{r}
boxcox(app.main) 
```

#You should see if the confidence interval includes 1 or 0. If it includes 1, you don't need a transformation. If it includes 0, you should use a log transformation. If it includes neither, use the optimal lambda. 

```{r}
boxcox(app.main, plotit = F)$x[which.max(boxcox(app.main, plotit = F)$y)] 
```

```{r}
names(app)
```

```{r}
pca_df <- app[,c("Price", "Develop", "X5Star", "CompSites", "Date", "Advert", "Users")]
pca_df.corr <- princomp(pca_df, cor=T)

barplot(pca_df.corr$loadings[,1], main='PC1 Loadings with Correlation Matrix')
```

```{r}
pca_df.corr$loadings[,1]
```

# Part 2 
```{r message=FALSE, warning=FALSE}
setwd("~/Desktop/Fall 2020 Classes/SYS4021/Source")
heart <- read.csv("heart.csv", sep=",", header=T)
heart$cp <- as.factor(heart$cp)
heart$sex <- as.factor(heart$sex)
head(heart)
```

```{r}
heart.11 = heart[,c("age", "sex", "cp", "diag")]
heart.glm.main <- glm(diag~., data = heart.11, family = binomial)
summary(heart.glm.main)
```

```{r}
heart.null <- glm(diag~1, data = heart.11, family = binomial)
anova(heart.null, heart.glm.main, test = "Chi")
```

```{r}
((exp(1)^(heart.glm.main$coefficients[2])) - 1)*100
```

```{r}
heart.glm.main$coefficients
```      

```{r}
names(heart)
```

```{r}
heart.15 = heart[,c("age", "sex", "cp", "restbps", "chol", "fbs", "diag")]
heart.glm.main15 <- glm(diag~., data = heart.15, family = binomial)
summary(heart.glm.main15)
```

```{r}
anova(heart.glm.main15, heart.glm.main, test = "Chi")
```
p > 0.05
Do not significantly affect 
Therefore reduce complexity and choose smaller

```{r}
names(heart)
```

```{r}
heart$restecg <- as.factor(heart$restecg)
heart.17 = heart[,c("age", "sex", "cp", "restbps", "chol", "fbs", "restecg", "diag")]
heart.glm.17 <- glm(diag~., data = heart.17, family = binomial)
heart.glm.17.step <- step(heart.glm.17, data = heart.17, family = binomial)
summary(heart.glm.17.step)
```

```{r}
heart.predict <- predict(heart.glm.17.step, type = "response")
score.table(heart.predict, heart$diag, 0.5)
```


```{r}
total = 40+160
fnr = 40/total
tpr = 160/total
1-tpr
fnr
```

```{r}
#FN = 0 
#1-TPR = FNR = 0 
#1-TPR = 0 
#TPR = 1
#Lowest FPR when TPR = 1
roc.plot.gg <- plot.roc.gg(heart.predict, heart$diag, "Step")
roc.plot.gg
```

```{r}
names(heart)
```

```{r}
#"sex", "cp", 
# "restecg",
pca_df <- heart[,c("age", "chol", "restbps", "fbs")]
pca_df.corr <- princomp(pca_df, cor=T)

barplot(pca_df.corr$loadings[,1], main='PC1 Loadings with Correlation Matrix')
```

```{r}
cumplot <- function(pca.obj, ...)
{
  xc <- cumsum(pca.obj$sdev^2)/sum(pca.obj$sdev^2)
  barplot(xc, ylim = c(0,1), main = "Proportion of Variance", ylab = "Proportion", names.arg = 1:length(pca.obj$sdev), xlab = "Components", ...)
  xc <- as.data.frame(xc)
  setDT(xc, keep.rownames=TRUE)[]
  names(xc)[names(xc) == "rn"] <- "Component"
  names(xc)[names(xc) == "xc"] <- "Proportion"
  return(xc)
}

cumplot(pca_df.corr, col = "grey")
```

```{r}
pca_df <- heart[,c("age", "chol", "restbps", "fbs")]
pca_df.corr <- princomp(pca_df, cor=T)
pca.glm75 <- pc.glm(pca_df.corr, 75, heart$diag)
pca.null <- pc.null(pca_df.corr, 85, heart$diag)
anova(pca.null, pca.glm75, test = "Chi")
```

```{r}
AIC(pca.glm75)
AIC(heart.glm.17.step)
```

```{r}
heart.pca.predict <- predict(pca.glm75, type = "response")
score.table(heart.pca.predict, heart$diag, 0.5)
```

```{r}
80+62
```

# Part 3 
```{r message=FALSE, warning=FALSE}
setwd("~/Desktop/Fall 2020 Classes/SYS4021/Source")
sunspot <- read.table("sunspot.csv", sep = ",", header = T)
head(sunspot)
```
```{r}
sunspot.ts<-ts(sunspot$sunspotarea)
```

```{r}
pg <- spec.pgram(sunspot.ts,demean=T,log='no', plot=FALSE)
spec <- data.frame(freq=pg$freq, spec=pg.NO2$spec)
ggplot(spec) + geom_line(aes(x=freq,y=spec)) + 
  ggtitle("Smooth Periodogram")
```

```{r}
# Find the peak
max.omega<-pg$freq[which(pg$spec==max(pg$spec))]
paste("Peak: ", max.omega)
nospans_period <- 1/max.omega
paste("Period: ", nospans_period)
```

```{r}
pg <- spec.pgram(sunspot.ts,spans=12,demean=T,log='no', plot=FALSE)
spec <- data.frame(freq=pg$freq, spec=pg.NO2$spec)
ggplot(spec) + geom_line(aes(x=freq,y=spec)) + 
  ggtitle("Smooth Periodogram")
```


```{r}
# Find the peak
max.omega<-pg$freq[which(pg$spec==max(pg$spec))]
paste("Peak: ", max.omega)
spans_period <- 1/max.omega
paste("Period: ", spans_period)
```

```{r}
avg_period <- (spans_period + nospans_period)/2
avg_period
```

```{r}
t <- c(1:(length(sunspot.ts)))
trend.seasonal <- lm(sunspot.ts ~ t + sin(2*pi*t/avg_period) + cos(2*pi*t/avg_period))
summary(trend.seasonal)
```

```{r}
ggAcf(trend.seasonal$residuals)
```

```{r}
ggPacf(trend.seasonal$residuals)
```

```{r}
automodel <- auto.arima(trend.seasonal$residuals, approximation=FALSE)
summary(automodel)
```

```{r}
automodel$arma
```

```{r}
ggAcf(automodel$residuals)
```

```{r}
ggtsdiag(automodel,gof.lag=20) 
```
